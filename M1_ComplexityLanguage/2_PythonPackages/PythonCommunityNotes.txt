PyPi Statistics!

08/02/2015: 54,986 packages registered on the PyPi index; 1,965,678,267 downloads

Hosts third party modules
-----------------------------

PyPi website was largely disorganized for research - its built for
finding the package you need quickly; with all information about it

METHOD:
    I used python packages SCRAPY and JSON to get the job done!
    First, I used SCRAPY to scrape the entire package index listing (60977 active package links). I followed each of those links to the package information page where I hoped to parse package history/upload dates and upload versions.
    
    python egg == logical structure
    
    Turns out, the tabular data included on those pages are not history of the file (similar to the python download page, where each row was a previous version of the product), it simply listed all the available versions of the downloaded (e.g., different compressioni/tarball types).
    
    So I parsed all information from the table into the JSON file but, only took the download date and size of the "Source" type, which was a consistent gz tarball download, same format as the python source code download. With this information, I hope to graph package size vs upload date
    and see the older ones be smaller than the more recent.
    
    Flaws: I'm unable to track the evolution of each package like I originally intended. I wanted to be able to include information about how packages grow with each update, ordered by their date. I.e., were most updated in sync with a new python release? Additionally, there was not information on the page to gather anything worthwhile about the popularity of each package. The information page included number of downloads (all versions) in the last day, week, and month, but unfortunately nothing long term. However, from the PyPi rankings page, http://pypi-ranking.info/alltime, users are able to determine the most popular packages of all time or of the current week. This information was not included in the report as it felt it added no value.
    
    NOTE: If you visit a particular package on their allistings, you can see a graph history of the number of downloads vs time.
    
        * Compare the top 20 to base 20?
        ** IGNORE ALL WITH '0' DOWNLOADS (needed to have at least 5 downloads)
        
        TOP 20:                  SIZE (B)
            distribute          141000
            virtualenv          1000000
            setuptools          620000
            certifi             164000
            requests            433000
            boto                1000000
            wincertstore        1000000
            pip                 1000000
            six                 28000
            pbr                 80000
            python-dateutil     190000
            lxml                3000000
            nose                270000
            simplejson          72000
            pika                70000
            Jinja2              369000
            MarkupSafe          13000
            docutils            1000000
            pytz                162000
            PyYAML              363000
            
            AVERAGE SIZE (of top 20):   548 750 B
            
        
        WORST 20:
            bitquant            13000
            Flask-Sillywalk     3000
            larry_nester        859
            hcpsdk              15000
            libres              76000
            ajenti.plugin.filemanager   6000
            ayame               156000
            gentle_django_mongo 4000
            CharByCharPrinter   990
            dionepaa            1000
            fitnoise            11000
            JSTinteract         7000
            chief-james         4000
            egnyte              23000
            atom                99000
            fleetmonger         5000
            celery-queued-once  2000
            htmd                8000
            b2gperf-v2.1        9000
            httpie-http2        1000
            
            Average size (of worst 200: )   21 567 B

            
    ** TODAY: Graphed the data, upload date vs number of instances
    (i.e., to try and find when the most popular times were)
    
    Formatted using jsonhandler.py
    Copied into excel; split text into columns
    Graphed!
    
    Most common:
    ('2015-02-12', 277), ('2015-02-09', 251), ('2015-02-11', 251)